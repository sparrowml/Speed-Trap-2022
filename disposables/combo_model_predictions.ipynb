{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from speed_trapv3.keypoints.model import SegmentationModel\n",
    "from speed_trapv3.detection.model import RetinaNet\n",
    "from speed_trapv3.detection.config import Config as DetConfig\n",
    "from speed_trapv3.keypoints.config import Config as KeyConfig\n",
    "from speed_trapv3.config import Config\n",
    "from speed_trapv3.utils import slugify, get_prediction_path\n",
    "from pathlib import Path\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "from speed_trapv3.keypoints.dataset import crop_and_resize,process_keypoints, keypoints_post_inference_processing\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import copy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model = RetinaNet().eval().cuda()\n",
    "detection_model.load(DetConfig.trained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoint_model = SegmentationModel().eval().cuda()\n",
    "keypoint_model.load(KeyConfig.trained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = T.Compose([T.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /code/data/datasets/temp_imgs/*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /code/data/datasets/keypoints/predictions/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /code/data/datasets/detection/predictions/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /code/data/datasets/common_hall/detection-keypoint-inference/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/600 [00:00<?, ?it/s]/tmp/ipykernel_266336/302179755.py:7: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img = imageio.imread(image_path)\n",
      "/usr/local/lib/python3.9/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|██████████| 600/600 [02:55<00:00,  3.42it/s]\n"
     ]
    }
   ],
   "source": [
    "image_paths = list(Config.images_directory.glob(\"*.jpg\"))\n",
    "random.shuffle(image_paths)\n",
    "score_threshold: float = 0.5\n",
    "# image_paths = image_paths[:5]\n",
    "for image_path in tqdm(image_paths):\n",
    "    slug = slugify(image_path)\n",
    "    img = imageio.imread(image_path)\n",
    "    img_h, img_w, _ = img.shape\n",
    "    aug_boxes = detection_model(img)\n",
    "    aug_boxes = aug_boxes[aug_boxes.scores > score_threshold].to_relative().to_tlbr()\n",
    "    boxes = aug_boxes.array[:,:4]\n",
    "    keypoints_list = []\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = (box * np.array([img_w, img_h, img_w, img_h])).astype(int)\n",
    "        roi_w = x2 - x1\n",
    "        roi_h = y2 - y1\n",
    "        roi_resized = crop_and_resize(box, img, KeyConfig.image_crop_size[0],KeyConfig.image_crop_size[1])\n",
    "        roi_resized_w, roi_resized_h = roi_resized.size\n",
    "        x = image_transform(roi_resized)\n",
    "        x = torch.unsqueeze(x, 0).cuda()\n",
    "        keypoints = keypoint_model(x)['keypoints'][0].detach().cpu().numpy()\n",
    "        keypoints = keypoints_post_inference_processing(\n",
    "            keypoints, roi_resized_w, roi_resized_h, roi_w, roi_h, x1, y1\n",
    "        )\n",
    "        keypoints_list.append(keypoints.astype(float).tolist())\n",
    "        img = cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), thickness=4)\n",
    "        img = cv2.circle(img, (int(keypoints[0][0]), int(keypoints[0][1])), radius=5, color=(0, 0, 255), thickness=-1) #Blue: Backtire\n",
    "        img = cv2.circle(img, (int(keypoints[1][0]), int(keypoints[1][1])), radius=5, color=(255, 0, 0), thickness=-1) #Red Front tire\n",
    "    im_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    save_path = '/code/data/datasets/temp_imgs'\n",
    "    filename = str(slug) + \".jpg\"\n",
    "    # box_path = Path(\"/code/data/datasets/detection/predictions\")\n",
    "    cv2.imwrite(os.path.join(save_path, filename), im_rgb)\n",
    "    aug_boxes.to_darwin_file(\n",
    "                output_path =  DetConfig.predictions_directory / (slug + \".json\"),\n",
    "                filename = filename,\n",
    "                label_names = [\"vehicle\"],\n",
    "            )\n",
    "    with open(KeyConfig.predictions_directory / f\"{slug}.json\", \"w\") as f:\n",
    "        f.write(json.dumps(keypoints_list))\n",
    "        \n",
    "\n",
    "    # boxes.to_file(get_prediction_path(slug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WBuBqS9h8_35559.json Did not have any predictions\n",
      "WBuBqS9h8_33146.json Did not have any predictions\n",
      "WBuBqS9h8_50410.json Did not have any predictions\n",
      "WBuBqS9h8_51004.json Did not have any predictions\n",
      "WBuBqS9h8_29341.json Did not have any predictions\n",
      "WBuBqS9h8_53284.json Did not have any predictions\n",
      "WBuBqS9h8_53024.json Did not have any predictions\n",
      "WBuBqS9h8_29312.json Did not have any predictions\n",
      "WBuBqS9h8_4513.json Did not have any predictions\n",
      "WBuBqS9h8_53311.json Did not have any predictions\n",
      "WBuBqS9h8_53418.json Did not have any predictions\n",
      "WBuBqS9h8_49399.json Did not have any predictions\n",
      "WBuBqS9h8_33161.json Did not have any predictions\n",
      "WBuBqS9h8_35539.json Did not have any predictions\n",
      "WBuBqS9h8_53148.json Did not have any predictions\n",
      "WBuBqS9h8_35582.json Did not have any predictions\n",
      "WBuBqS9h8_151.json Did not have any predictions\n",
      "WBuBqS9h8_35600.json Did not have any predictions\n",
      "WBuBqS9h8_50896.json Did not have any predictions\n"
     ]
    }
   ],
   "source": [
    "multi_model_path = \"/code/data/datasets/common_hall/detection-keypoint-inference\"\n",
    "existing_list = os.listdir(\"/root/.darwin/datasets/sparrow-computing/kj_speedtrap/releases/allv1/annotations\")\n",
    "detection_annotation_files = os.listdir(DetConfig.predictions_directory)\n",
    "for detection_annotation_file in detection_annotation_files:\n",
    "    if detection_annotation_file not in existing_list:\n",
    "        detection_file = open(DetConfig.predictions_directory/detection_annotation_file)\n",
    "        detection_annotation_content = json.load(detection_file)\n",
    "        if (KeyConfig.predictions_directory/detection_annotation_file).exists():\n",
    "            keypoint_file = open(KeyConfig.predictions_directory/detection_annotation_file)\n",
    "            keypoint_annotation_content = json.load(keypoint_file)\n",
    "            # for idx, tire in enumerate(KeyConfig.keypoint_names):\n",
    "            #     key_dict = {}\n",
    "            #     key_dict[\"name\"] = tire\n",
    "            #     key_dict[\"keypoint\"] = {\"x\": keypoint_annotation_content[idx][0], \"y\": keypoint_annotation_content[idx][1]}\n",
    "            #     detection_annotation_content['annotations'].append(key_dict)\n",
    "            for key_pair in keypoint_annotation_content:\n",
    "                for idx, tire in enumerate(KeyConfig.keypoint_names):\n",
    "                    key_dict = {}\n",
    "                    x, y = key_pair[idx]\n",
    "                    key_dict[\"name\"] =  tire\n",
    "                    key_dict[\"keypoint\"] = {\n",
    "                        \"x\": x, \"y\":y\n",
    "                    }\n",
    "                    # key_dict[\"x\"] =  x\n",
    "                    # key_dict[\"y\"] = y\n",
    "                    detection_annotation_content['annotations'].append(key_dict)\n",
    "        if len(detection_annotation_content[\"annotations\"]) > 0:\n",
    "            with open(Path(multi_model_path)/detection_annotation_file, \"w\") as f:\n",
    "                f.write(json.dumps(detection_annotation_content))\n",
    "        else:\n",
    "            print(detection_annotation_file, \"Did not have any predictions\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bounding_box': {'x': 602.1806030273438,\n",
       "   'y': 345.3334655761719,\n",
       "   'w': 230.27789306640625,\n",
       "   'h': 132.62420654296875},\n",
       "  'name': 'vehicle'},\n",
       " {'bounding_box': {'x': 892.2577514648438,\n",
       "   'y': 346.2511291503906,\n",
       "   'w': 372.38116455078125,\n",
       "   'h': 294.5596618652344},\n",
       "  'name': 'vehicle'},\n",
       " {'bounding_box': {'x': 456.66058349609375,\n",
       "   'y': 338.255859375,\n",
       "   'w': 68.503173828125,\n",
       "   'h': 80.26443481445312},\n",
       "  'name': 'vehicle'},\n",
       " {'name': 'back_tire',\n",
       "  'keypoint': {'x': 605.3202099737533, 'y': 459.26356589147287}},\n",
       " {'name': 'front_tire',\n",
       "  'keypoint': {'x': 655.727034120735, 'y': 472.90697674418607}},\n",
       " {'name': 'back_tire',\n",
       "  'keypoint': {'x': 920.8031496062993, 'y': 564.7906976744187}},\n",
       " {'name': 'front_tire',\n",
       "  'keypoint': {'x': 1118.51968503937, 'y': 624.8062015503876}},\n",
       " {'name': 'back_tire',\n",
       "  'keypoint': {'x': 467.0472440944882, 'y': 354.95090439276487}},\n",
       " {'name': 'front_tire', 'keypoint': {'x': 456.0, 'y': 338.0}}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_annotation_content['annotations']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
