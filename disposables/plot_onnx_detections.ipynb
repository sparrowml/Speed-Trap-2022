{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import onnxruntime as ort\n",
    "import cv2\n",
    "import imageio\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from speed_trapv3.tracking.tracking import get_video_properties, transform_image#, get_frame_box\n",
    "from speed_trapv3.tracking.config import Config\n",
    "from sparrow_datums import AugmentedBoxTracking, BoxTracking, FrameBoxes, PType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/code/data/datasets/common_hall/source_video/25_resampled_vid.mp4\"\n",
    "model_path = \"/code/data/models/detection/model.onnx\"\n",
    "temp_save_path = \"/code/data/datasets/temp_imgs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1280,  720, 1280,  720])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([Config.image_width, Config.image_height] * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_box(\n",
    "    boxes: np.ndarray,\n",
    "    scores: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    image_width: int,\n",
    "    image_height: int,\n",
    ") -> tuple[FrameBoxes, FrameBoxes]:\n",
    "    \"\"\"Convert bounding boxes from numpy array into ball and player FrameBoxes.\n",
    "    Parameters\n",
    "    ----------\n",
    "    boxes\n",
    "        (n, 4) boxes in absolute tlbr format with shape Config.image_size\n",
    "    scores\n",
    "        Confidence that each box is an object\n",
    "    labels\n",
    "        Class indices (0 == ball, 1 == active player)\n",
    "    Returns\n",
    "    -------\n",
    "    ball_boxes, player_boxes\n",
    "        Output boxes with width/height corresponding to the input video\n",
    "    \"\"\"\n",
    "    relative_boxes = boxes / np.array([Config.image_width, Config.image_height] * 2)\n",
    "    vehicle_mask = np.logical_and(\n",
    "        labels == Config.vehicle_class_index, scores > Config.vehicle_score_threshold\n",
    "    )\n",
    "    vehicle_boxes = FrameBoxes(\n",
    "        relative_boxes[vehicle_mask],\n",
    "        PType.relative_tlbr,\n",
    "        image_width=image_width,\n",
    "        image_height=image_height,\n",
    "    )\n",
    "    return vehicle_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 21:43:20.363665676 [W:onnxruntime:, session_state.cc:1030 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\n",
      "2022-10-25 21:43:20.363679243 [W:onnxruntime:, session_state.cc:1032 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\n",
      " 23%|██▎       | 140/599 [00:12<00:39, 11.51it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m vehicle_boxes \u001b[39m=\u001b[39m vehicle_boxes\u001b[39m.\u001b[39mto_absolute()\n\u001b[1;32m     19\u001b[0m vehicle_boxes \u001b[39m=\u001b[39m vehicle_boxes\u001b[39m.\u001b[39mto_tlbr()\n\u001b[0;32m---> 20\u001b[0m cv2\u001b[39m.\u001b[39mimwrite(temp_save_path \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.jpg\u001b[39m\u001b[39m\"\u001b[39m, data)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "video_path = Path(video_path)\n",
    "slug = video_path.name.removesuffix(\".mp4\")\n",
    "sess = ort.InferenceSession(str(model_path), providers=[\"CUDAExecutionProvider\"])\n",
    "fps, n_frames = get_video_properties(video_path)\n",
    "reader = imageio.get_reader(video_path)\n",
    "for i in tqdm(range(n_frames)):\n",
    "    # data = reader.get_data(i)\n",
    "    data = cv2.imread(\"/code/data/datasets/images/WBuBqS9h8_261.jpg\")\n",
    "    data = cv2.rectangle(\n",
    "        data, (450, 200), (1280, 720), thickness=5, color=(0, 255, 0)\n",
    "    )\n",
    "    input_height, input_width = data.shape[:2]\n",
    "    x = transform_image(data)\n",
    "    boxes, scores, labels = sess.run(None, {\"input\": x[0]})\n",
    "    vehicle_boxes = get_frame_box(\n",
    "        boxes, scores, labels, image_width=input_width, image_height=input_height\n",
    "    )\n",
    "    vehicle_boxes = vehicle_boxes.to_absolute()\n",
    "    vehicle_boxes = vehicle_boxes.to_tlbr()\n",
    "    cv2.imwrite(temp_save_path + f\"/{i}.jpg\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrameBoxes([[ 277.68785265,    0.        ,  389.69523112,    0.        ],\n",
       "            [   0.        ,  307.87399292,  224.91179742,  307.87399292],\n",
       "            [2275.55555556,    0.        , 2275.55555556,    0.        ],\n",
       "            [1859.18424479,   55.68155193, 1859.18424479,   55.68155193],\n",
       "            [2275.55555556,    0.        , 2275.55555556,    0.        ],\n",
       "            [   0.        ,    0.        ,  195.58865017,    0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.56199417e+02,  0.00000000e+00,  2.19203568e+02,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  5.47331543e+02,  1.26512886e+02,\n",
       "         5.47331543e+02],\n",
       "       [ 1.28000000e+03,  0.00000000e+00,  1.28000000e+03,\n",
       "         0.00000000e+00],\n",
       "       [ 1.04579114e+03,  9.89894257e+01,  1.04579114e+03,\n",
       "         9.89894257e+01],\n",
       "       [ 1.28000000e+03,  0.00000000e+00,  1.28000000e+03,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  1.10018616e+02,\n",
       "         0.00000000e+00],\n",
       "       [ 1.28000000e+03,  0.00000000e+00,  1.28000000e+03,\n",
       "         0.00000000e+00],\n",
       "       [ 9.03964600e+02,  0.00000000e+00,  9.03973145e+02,\n",
       "         0.00000000e+00],\n",
       "       [ 8.76972656e+02,  0.00000000e+00,  1.05073535e+03,\n",
       "         0.00000000e+00],\n",
       "       [ 8.00010193e+02,  7.20000000e+02,  8.00010193e+02,\n",
       "         7.20000000e+02],\n",
       "       [-1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        -1.00000000e+00],\n",
       "       [-1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        -1.00000000e+00],\n",
       "       [-1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        -1.00000000e+00],\n",
       "       [-1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        -1.00000000e+00],\n",
       "       [-1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        -1.00000000e+00],\n",
       "       [-1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        -1.00000000e+00],\n",
       "       [-1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        -1.00000000e+00],\n",
       "       [-1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        -1.00000000e+00],\n",
       "       [-1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        -1.00000000e+00],\n",
       "       [-1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        -1.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_h, img_w, _ = data.shape\n",
    "pop = (boxes / np.array([img_w, img_h, img_w, img_h]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes.astype(int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
