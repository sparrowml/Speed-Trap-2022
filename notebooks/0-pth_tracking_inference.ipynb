{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script can generate the tracking inference (.gz) file given a pytorch detection model and a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speed_trapv3.keypoints.model import SegmentationModel\n",
    "from speed_trapv3.detection.model import RetinaNet\n",
    "from speed_trapv3.detection.config import Config as DetConfig\n",
    "from speed_trapv3.keypoints.config import Config as KeyConfig\n",
    "from speed_trapv3.tracking.config import Config as TrackConfig\n",
    "from speed_trapv3.config import Config\n",
    "from speed_trapv3.utils import slugify, get_prediction_path\n",
    "from pathlib import Path\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "from speed_trapv3.keypoints.dataset import crop_and_resize,process_keypoints, keypoints_post_inference_processing\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "from speed_trapv3.tracking.tracking import get_video_properties, transform_image, write_to_json#, get_frame_box\n",
    "from sparrow_tracky import Tracker, euclidean_distance\n",
    "from sparrow_datums import AugmentedBoxTracking, BoxTracking, FrameBoxes, PType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box_properties(box_in):\n",
    "    \"\"\"Split the augmented box into numpy arrays.\n",
    "    Args:\n",
    "        box_in (FrameAugmentedBoxes): FrameAugmentedBoxes produced by the model.\n",
    "    Returns:\n",
    "        tuple: A tuple of three numpy arrays.\n",
    "    \"\"\"\n",
    "    box = box_in\n",
    "    labels = box.labels\n",
    "    scores = box.scores\n",
    "    box = box.array[:, 0: 4]\n",
    "    return (box, scores, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_path(path_in):\n",
    "    \"\"\"Check if a given path exists and make one if it doesn't.\n",
    "\n",
    "    Args:\n",
    "        path_in (str): _description_ Input path that might need to be created.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path_in):\n",
    "        os.mkdir(path_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/code/data/datasets/common_hall/source_video/25_resampled_vid.mp4\"\n",
    "model_path = \"/code/data/models/detection/model.pth\"\n",
    "temp_save_path = \"/code/data/datasets/temp_imgs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model = RetinaNet().eval().cuda()\n",
    "detection_model.load(DetConfig.trained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps, n_frames = get_video_properties(video_path)\n",
    "reader = imageio.get_reader(video_path)\n",
    "vehicle_tracker = Tracker(TrackConfig.vehicle_iou_threshold)\n",
    "slug = \"hard_coded\"\n",
    "for i in tqdm(range(n_frames)):\n",
    "    data = reader.get_data(i)\n",
    "    data = cv2.rectangle(\n",
    "        data, (450, 200), (1280, 720), thickness=5, color=(0, 255, 0)\n",
    "    )\n",
    "    # img = imageio.imread(image_path)\n",
    "    img_h, img_w, _ = data.shape\n",
    "    aug_boxes = detection_model(data)\n",
    "    aug_boxes = aug_boxes[aug_boxes.scores > TrackConfig.vehicle_score_threshold]\n",
    "    boxes = aug_boxes.array[:,:4]\n",
    "    vehicle_boxes = FrameBoxes(\n",
    "    boxes,\n",
    "    PType.absolute_tlbr,  # (x1, y1, x2, y2) in absolute pixel coordinates [With respect to the original image size]\n",
    "    image_width=data.shape[1],\n",
    "    image_height=data.shape[0],\n",
    "    ).to_relative()  \n",
    "    vehicle_tracker.track(vehicle_boxes)\n",
    "make_path(str(TrackConfig.prediction_directory / slug))\n",
    "vehicle_chunk = vehicle_tracker.make_chunk(fps, TrackConfig.vehicle_tracklet_length)\n",
    "vehicle_chunk.to_file(\n",
    "    TrackConfig.prediction_directory / slug / f\"{slug}_vehicle.json.gz\"\n",
    "    )\n",
    "    # for box in boxes:\n",
    "    #     x1, y1, x2, y2 = (box * np.array([img_w, img_h, img_w, img_h])).astype(int)\n",
    "    #     data = cv2.rectangle(data, (x1, y1), (x2, y2), (255, 0, 255), thickness=4)\n",
    "    # im_rgb = cv2.cvtColor(data, cv2.COLOR_BGR2RGB)\n",
    "    # save_path = '/code/data/datasets/temp_imgs'\n",
    "    # filename = str(i) + \".jpg\"\n",
    "    # cv2.imwrite(os.path.join(save_path, filename), im_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speed_trapv3.tracking.tracking import get_video_properties, transform_image, write_to_json\n",
    "from pathlib import Path\n",
    "gz_path = Path(\"/code/data/datasets/tracking/predictions/hard_coded/hard_coded_vehicle.json.gz\")\n",
    "video_path = \"/code/data/datasets/common_hall/source_video/25_resampled_vid.mp4\"\n",
    "write_to_json(gz_path, video_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
