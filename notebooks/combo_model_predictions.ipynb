{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from speed_trapv3.keypoints.model import SegmentationModel\n",
    "from speed_trapv3.detection.model import RetinaNet\n",
    "from speed_trapv3.detection.config import Config as DetConfig\n",
    "from speed_trapv3.keypoints.config import Config as KeyConfig\n",
    "from speed_trapv3.config import Config\n",
    "from speed_trapv3.utils import slugify, get_prediction_path\n",
    "from pathlib import Path\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "from speed_trapv3.keypoints.dataset import crop_and_resize,process_keypoints\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model = RetinaNet().eval().cuda()\n",
    "detection_model.load(DetConfig.trained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoint_model = SegmentationModel().eval().cuda()\n",
    "keypoint_model.load(KeyConfig.trained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = T.Compose([T.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /code/data/datasets/temp_imgs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]/tmp/ipykernel_160447/771158575.py:7: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img = imageio.imread(image_path)\n",
      "/usr/local/lib/python3.9/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.77it/s]\n"
     ]
    }
   ],
   "source": [
    "image_paths = list(Config.images_directory.glob(\"*.jpg\"))\n",
    "random.shuffle(image_paths)\n",
    "score_threshold: float = 0.5\n",
    "image_paths = image_paths[:3]\n",
    "for image_path in tqdm(image_paths):\n",
    "    slug = slugify(image_path)\n",
    "    img = imageio.imread(image_path)\n",
    "    img_h, img_w, _ = img.shape\n",
    "    boxes = detection_model(img)\n",
    "    boxes = boxes[boxes.scores > score_threshold].to_relative().to_tlbr()\n",
    "    boxes = boxes.array[:,:4]\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = (box * np.array([img_w, img_h, img_w, img_h])).astype(int)\n",
    "        roi_w = x2 - x1\n",
    "        roi_h = y2 - y1\n",
    "        roi_resized = crop_and_resize(box, img, KeyConfig.image_crop_size[0],KeyConfig.image_crop_size[1])\n",
    "        roi_resized_w, roi_resized_h = roi_resized.size\n",
    "        x = image_transform(roi_resized)\n",
    "        x = torch.unsqueeze(x, 0).cuda()\n",
    "        keypoints = keypoint_model(x)['keypoints'][0].detach().cpu().numpy()\n",
    "        keypoints =  keypoints/ np.array([roi_resized_w, roi_resized_h])#convert to relative\n",
    "        keypoints = keypoints * np.array([roi_w, roi_h])\n",
    "        keypoints = keypoints + np.array([x1, y1])\n",
    "        img = cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), thickness=4)\n",
    "        img = cv2.circle(img, (int(keypoints[0][0]), int(keypoints[0][1])), radius=5, color=(0, 0, 255), thickness=-1) #Blue: Backtire\n",
    "        img = cv2.circle(img, (int(keypoints[1][0]), int(keypoints[1][1])), radius=5, color=(255, 0, 0), thickness=-1) #Red Front tire\n",
    "    im_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    save_path = '/code/data/datasets/temp_imgs'\n",
    "    filename = str(slug) + \".jpg\"\n",
    "    cv2.imwrite(os.path.join(save_path, filename), im_rgb)\n",
    "        \n",
    "\n",
    "    # boxes.to_file(get_prediction_path(slug))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
