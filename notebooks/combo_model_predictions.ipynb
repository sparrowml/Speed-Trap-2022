{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speed_trapv3.keypoints.model import SegmentationModel\n",
    "from speed_trapv3.detection.model import RetinaNet\n",
    "from speed_trapv3.detection.config import Config as DetConfig\n",
    "from speed_trapv3.keypoints.config import Config as KeyConfig\n",
    "from speed_trapv3.config import Config\n",
    "from speed_trapv3.utils import slugify, get_prediction_path\n",
    "from pathlib import Path\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "from speed_trapv3.keypoints.dataset import crop_and_resize,process_keypoints, keypoints_post_inference_processing\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import copy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model = RetinaNet().eval().cuda()\n",
    "detection_model.load(DetConfig.trained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_model = SegmentationModel().eval().cuda()\n",
    "keypoint_model.load(KeyConfig.trained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = T.Compose([T.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /code/data/datasets/temp_imgs/*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /code/data/datasets/keypoints/predictions/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /code/data/datasets/detection/predictions/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /code/data/datasets/common_hall/detection-keypoint-inference/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = list(Config.images_directory.glob(\"*.jpg\"))\n",
    "random.shuffle(image_paths)\n",
    "score_threshold: float = 0.5\n",
    "# image_paths = image_paths[:5]\n",
    "for image_path in tqdm(image_paths):\n",
    "    slug = slugify(image_path)\n",
    "    img = imageio.imread(image_path)\n",
    "    img_h, img_w, _ = img.shape\n",
    "    aug_boxes = detection_model(img)\n",
    "    aug_boxes = aug_boxes[aug_boxes.scores > score_threshold].to_relative().to_tlbr()\n",
    "    boxes = aug_boxes.array[:,:4]\n",
    "    keypoints_list = []\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = (box * np.array([img_w, img_h, img_w, img_h])).astype(int)\n",
    "        roi_w = x2 - x1\n",
    "        roi_h = y2 - y1\n",
    "        roi_resized = crop_and_resize(box, img, KeyConfig.image_crop_size[0],KeyConfig.image_crop_size[1])\n",
    "        roi_resized_w, roi_resized_h = roi_resized.size\n",
    "        x = image_transform(roi_resized)\n",
    "        x = torch.unsqueeze(x, 0).cuda()\n",
    "        keypoints = keypoint_model(x)['keypoints'][0].detach().cpu().numpy()\n",
    "        keypoints = keypoints_post_inference_processing(\n",
    "            keypoints, roi_resized_w, roi_resized_h, roi_w, roi_h, x1, y1\n",
    "        )\n",
    "        keypoints_list.append(keypoints.astype(float).tolist())\n",
    "        img = cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), thickness=4)\n",
    "        img = cv2.circle(img, (int(keypoints[0][0]), int(keypoints[0][1])), radius=5, color=(0, 0, 255), thickness=-1) #Blue: Backtire\n",
    "        img = cv2.circle(img, (int(keypoints[1][0]), int(keypoints[1][1])), radius=5, color=(255, 0, 0), thickness=-1) #Red Front tire\n",
    "    im_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    save_path = '/code/data/datasets/temp_imgs'\n",
    "    filename = str(slug) + \".jpg\"\n",
    "    # box_path = Path(\"/code/data/datasets/detection/predictions\")\n",
    "    cv2.imwrite(os.path.join(save_path, filename), im_rgb)\n",
    "    aug_boxes.to_darwin_file(\n",
    "                output_path =  DetConfig.predictions_directory / (slug + \".json\"),\n",
    "                filename = filename,\n",
    "                label_names = [\"vehicle\"],\n",
    "            )\n",
    "    with open(KeyConfig.predictions_directory / f\"{slug}.json\", \"w\") as f:\n",
    "        f.write(json.dumps(keypoints_list))\n",
    "        \n",
    "\n",
    "    # boxes.to_file(get_prediction_path(slug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model_path = \"/code/data/datasets/common_hall/detection-keypoint-inference\"\n",
    "existing_list = os.listdir(\"/root/.darwin/datasets/sparrow-computing/kj_speedtrap/releases/allv1/annotations\")\n",
    "detection_annotation_files = os.listdir(DetConfig.predictions_directory)\n",
    "for detection_annotation_file in detection_annotation_files:\n",
    "    if detection_annotation_file not in existing_list:\n",
    "        detection_file = open(DetConfig.predictions_directory/detection_annotation_file)\n",
    "        detection_annotation_content = json.load(detection_file)\n",
    "        if (KeyConfig.predictions_directory/detection_annotation_file).exists():\n",
    "            keypoint_file = open(KeyConfig.predictions_directory/detection_annotation_file)\n",
    "            keypoint_annotation_content = json.load(keypoint_file)\n",
    "            # for idx, tire in enumerate(KeyConfig.keypoint_names):\n",
    "            #     key_dict = {}\n",
    "            #     key_dict[\"name\"] = tire\n",
    "            #     key_dict[\"keypoint\"] = {\"x\": keypoint_annotation_content[idx][0], \"y\": keypoint_annotation_content[idx][1]}\n",
    "            #     detection_annotation_content['annotations'].append(key_dict)\n",
    "            for key_pair in keypoint_annotation_content:\n",
    "                for idx, tire in enumerate(KeyConfig.keypoint_names):\n",
    "                    key_dict = {}\n",
    "                    x, y = key_pair[idx]\n",
    "                    key_dict[\"name\"] =  tire\n",
    "                    key_dict[\"keypoint\"] = {\n",
    "                        \"x\": x, \"y\":y\n",
    "                    }\n",
    "                    # key_dict[\"x\"] =  x\n",
    "                    # key_dict[\"y\"] = y\n",
    "                    detection_annotation_content['annotations'].append(key_dict)\n",
    "        if len(detection_annotation_content[\"annotations\"]) > 0:\n",
    "            with open(Path(multi_model_path)/detection_annotation_file, \"w\") as f:\n",
    "                f.write(json.dumps(detection_annotation_content))\n",
    "        else:\n",
    "            print(detection_annotation_file, \"Did not have any predictions\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_annotation_content['annotations']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
