{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we write the speed algorithm output into a video. This creates the final output of our speed trap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sparrow_datums import Boxes\n",
    "import numpy as np\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional\n",
    "import io\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from sparrow_datums import AugmentedBoxTracking, BoxTracking, FrameBoxes, PType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from speed_trapv3.keypoints.model import SegmentationModel\n",
    "from speed_trapv3.keypoints.config import Config as KeyConfig\n",
    "from speed_trapv3.keypoints.dataset import crop_and_resize,process_keypoints, keypoints_post_inference_processing\n",
    "from speed_trapv3.tracking.tracking import get_video_properties, transform_image, write_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECTION_AREA_START_X = 800\n",
    "INCLUSION_RADIUS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '/code/data/datasets/common_hall/source_video/25_resampled_vid.mp4'\n",
    "gz_path = '/code/data/datasets/tracking/predictions/hard_coded/hard_coded_vehicle.json.gz'\n",
    "video_save_path = '/code/data/datasets/common_hall/tracking_outputs/final_hardcoded_video.mp4'\n",
    "framewise_aggregation_path = '/code/data/datasets/common_hall/tracking_outputs/framewise_aggregation.json'\n",
    "objectwise_aggregation_path = '/code/data/datasets/common_hall/tracking_outputs/objectwise_aggregation.json'\n",
    "speed_log_path = '/code/data/datasets/common_hall/tracking_outputs/speed_log.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoint_model = SegmentationModel().eval().cuda()\n",
    "keypoint_model.load(KeyConfig.trained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(speed_log_path, 'r')\n",
    "speed_log = json.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(framewise_aggregation_path, 'r')\n",
    "framewise_aggregation = json.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(objectwise_aggregation_path, 'r')\n",
    "objectwise_aggregation = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_inclusion(_x, _y, _cx, _cy, _r):\n",
    "    return (_x - _cx)**2 + (_y -_cy)**2 < _r**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "599it [04:29,  2.22it/s]\n"
     ]
    }
   ],
   "source": [
    "reader = imageio.get_reader(video_path)\n",
    "fps = reader.get_meta_data()[\"fps\"]\n",
    "frame_border = True\n",
    "class_label: bool = False\n",
    "score_label: bool = False\n",
    "object_label: bool = True\n",
    "rule0 = True\n",
    "rule1 = True\n",
    "rule2 = True\n",
    "vehicle_chunk = AugmentedBoxTracking.from_box_tracking(BoxTracking.from_file(gz_path))\n",
    "vehicle_tracklet_list = BoxTracking.from_file(gz_path).to_dict()[\"object_ids\"]\n",
    "speed_log_vehice_ids = list(speed_log.keys())\n",
    "image_transform = T.Compose([T.ToTensor()])\n",
    "with imageio.get_writer(\n",
    "    video_save_path, mode=\"I\", fps=fps, macro_block_size=None\n",
    ") as writer:\n",
    "#@TODO: Uncomment if you want to write to a JSON\n",
    "    # aggregated_predictions = []  # Len is equal to to the number of frames.\n",
    "    frame_idx = 0\n",
    "    object_count_log = {}\n",
    "    last_known_speed = {}\n",
    "    for img, vehicle_boxes in tqdm(zip(reader, vehicle_chunk)):\n",
    "        frame_log = {}\n",
    "        frame_log[\"frame_idx\"] = frame_idx\n",
    "        frame_log[\"annotations\"] = []\n",
    "        boxes = vehicle_boxes  # vehicle_boxes is a len = 16 list where unavailable objects are nan.\n",
    "        height, width = img.shape[:2]\n",
    "        fig = plt.figure(frameon=False, figsize=(width / 100, height / 100), dpi=100)\n",
    "        fig.add_axes((0, 0, 1, 1))\n",
    "        plt.imshow(img)\n",
    "        if frame_border:\n",
    "            plt.plot(\n",
    "                [450, 1280, 1280, 450, 450], [200, 200, 720, 720, 200], lw=2, c=\"green\"\n",
    "            )\n",
    "        for i, box in enumerate(boxes.to_absolute()):\n",
    "            object_log = {}\n",
    "            if not np.isfinite(box.x):\n",
    "                continue\n",
    "            x1 = np.clip(box.x1, 2, width - 2)\n",
    "            x2 = np.clip(box.x2, 2, width - 2)\n",
    "            y1 = np.clip(box.y1, 2, height - 2)\n",
    "            y2 = np.clip(box.y2, 2, height - 2)\n",
    "            # rule #0\n",
    "            if rule0 == True and (\n",
    "                x1 < 600 or x1 >= 1100\n",
    "            ):  # if the object is located either in far-left or far-right, ignore it.\n",
    "                continue\n",
    "            color: Optional[str] = None\n",
    "            text_strings: list[str] = []\n",
    "            if class_label:\n",
    "                text_strings.append(f\"class: {int(box.label)}\")\n",
    "                color = f\"C{int(box.label)}\"\n",
    "            if score_label:\n",
    "                text_strings.append(f\"score: {box.score:.2f}\")\n",
    "            if object_label:\n",
    "                if (\n",
    "                    str(i) in speed_log_vehice_ids\n",
    "                    and str(frame_idx) in speed_log[str(i)]\n",
    "                    and speed_log[str(i)][str(frame_idx)] >= 0\n",
    "                ):\n",
    "                    text_strings.append(f\"object_id: {i}\")\n",
    "                    text_strings.append(\n",
    "                        f\"\\n current speed: {speed_log[str(i)][str(frame_idx)]} m/S\"\n",
    "                    )\n",
    "                    last_known_speed[str(i)] = speed_log[str(i)][str(frame_idx)]\n",
    "                elif str(i) in speed_log_vehice_ids and str(i) in last_known_speed:\n",
    "                    text_strings.append(f\"object_id: {i}\")\n",
    "                    text_strings.append(\n",
    "                        f\"\\n current speed: {last_known_speed[str(i)]} m/S\"\n",
    "                    )\n",
    "                else:\n",
    "                    text_strings.append(f\"object_id: {i}\")\n",
    "                if color is None:\n",
    "                    color = f\"C{i}\"\n",
    "            if color is None:\n",
    "                color = \"C0\"\n",
    "            plt.text(\n",
    "                x1 + 3,\n",
    "                y1 - 8,\n",
    "                \", \".join(text_strings),\n",
    "                backgroundcolor=(1, 1, 1, 0.5),\n",
    "                c=\"black\",\n",
    "                size=8,\n",
    "            )\n",
    "            plt.plot([x1, x2, x2, x1, x1], [y1, y1, y2, y2, y1], lw=2, c=color)\n",
    "            roi_w = x2 - x1\n",
    "            roi_h = y2 - y1\n",
    "            roi_resized = crop_and_resize(\n",
    "                box.to_relative().array[:4],\n",
    "                img,\n",
    "                KeyConfig.image_crop_size[0],\n",
    "                KeyConfig.image_crop_size[1],\n",
    "            )\n",
    "            roi_resized_w, roi_resized_h = roi_resized.size\n",
    "            x = image_transform(roi_resized)\n",
    "            x = torch.unsqueeze(x, 0).cuda()\n",
    "            keypoints = keypoint_model(x)[\"keypoints\"][0].detach().cpu().numpy()\n",
    "            keypoints = keypoints_post_inference_processing(\n",
    "                keypoints, roi_resized_w, roi_resized_h, roi_w, roi_h, x1, y1\n",
    "            )\n",
    "            heatmaps = keypoint_model(x)['heatmaps'].detach().cpu()\n",
    "            keypoints_scores = list(np.amax(torch.flatten(heatmaps, 2).numpy(), axis=-1)[0])\n",
    "            #@TODO: Enable the object_log and frame_log if you want to write to JSON.\n",
    "            # object_log[\"keypoints\"] = [list(keypoints[0]), list(keypoints[1])]\n",
    "            # object_log['keypoints_scores'] = [keypoints_scores[0].item(), keypoints_scores[1].item()]\n",
    "            # object_log[\"object_id\"] = i\n",
    "            # object_log[\"bounding_box\"] = list(box.array[:4])\n",
    "            # object_log[\"object_tracklet_id\"] = vehicle_tracklet_list[i]\n",
    "            # frame_log[\"annotations\"].append(object_log)\n",
    "            back_tire_x, back_tire_y = keypoints[0]\n",
    "            front_tire_x, front_tire_y = keypoints[1]\n",
    "            #rule #1 and rule #2\n",
    "            # TF\n",
    "            if rule1 == True and rule2 ==False:\n",
    "                if (back_tire_y > y1 + int((y2 - y1)/2)):#if the tire located in the lower half of the bbx, plot it.\n",
    "                    plt.plot(back_tire_x, back_tire_y, marker=\"o\", color=\"red\")\n",
    "                if (front_tire_y > y1 + int((y2 - y1)/2)):\n",
    "                    plt.plot(front_tire_x, front_tire_y, marker=\"o\", color=\"blue\")\n",
    "            # FT\n",
    "            if rule1 == False and rule2 ==True:\n",
    "                if validate_inclusion(back_tire_x, back_tire_y, front_tire_x, front_tire_y, INCLUSION_RADIUS):\n",
    "                    if np.array(object_log['keypoints_scores']).argmax() == 0:\n",
    "                        plt.plot(back_tire_x, back_tire_y, marker=\"o\", color=\"red\")\n",
    "                    else:\n",
    "                        plt.plot(front_tire_x, front_tire_y, marker=\"o\", color=\"blue\")\n",
    "                else:\n",
    "                    plt.plot(back_tire_x, back_tire_y, marker=\"o\", color=\"red\")\n",
    "                    plt.plot(front_tire_x, front_tire_y, marker=\"o\", color=\"blue\")\n",
    "            # TT\n",
    "            if rule1 == True and rule2 ==True:\n",
    "                if (back_tire_y > y1 + int((y2 - y1)/2)):\n",
    "                    if validate_inclusion(back_tire_x, back_tire_y, front_tire_x, front_tire_y, INCLUSION_RADIUS):\n",
    "                        if np.array(object_log['keypoints_scores']).argmax() == 0:\n",
    "                            plt.plot(back_tire_x, back_tire_y, marker=\"o\", color=\"red\")\n",
    "                        elif (front_tire_y > y1 + int((y2 - y1)/2)):\n",
    "                            plt.plot(front_tire_x, front_tire_y, marker=\"o\", color=\"blue\")\n",
    "                    elif (front_tire_y > y1 + int((y2 - y1)/2)):\n",
    "                        plt.plot(back_tire_x, back_tire_y, marker=\"o\", color=\"red\")\n",
    "                        plt.plot(front_tire_x, front_tire_y, marker=\"o\", color=\"blue\")\n",
    "                    else:\n",
    "                        plt.plot(back_tire_x, back_tire_y, marker=\"o\", color=\"red\")\n",
    "                elif (front_tire_y > y1 + int((y2 - y1)/2)):\n",
    "                    plt.plot(front_tire_x, front_tire_y, marker=\"o\", color=\"blue\")\n",
    "\n",
    "            # FF\n",
    "            if rule1 == False and rule2 ==False:\n",
    "                plt.plot(back_tire_x, back_tire_y, marker=\"o\", color=\"red\")\n",
    "                plt.plot(front_tire_x, front_tire_y, marker=\"o\", color=\"blue\")\n",
    "\n",
    "            if x1 > DETECTION_AREA_START_X and vehicle_tracklet_list[i] not in object_count_log:\n",
    "                object_count_log[vehicle_tracklet_list[i]] = True\n",
    "        #@TODO: uncomment if you want to write to JSON\n",
    "        # aggregated_predictions.append(frame_log)\n",
    "        plt.text(\n",
    "            100,\n",
    "            100,\n",
    "            f\"Vehicle Count = {len(object_count_log)}\",\n",
    "            backgroundcolor=(1, 0.5, 1, 0.5),\n",
    "            c=\"black\",\n",
    "            # size=20,\n",
    "            fontsize=16,\n",
    "        )\n",
    "        buffer = io.BytesIO()\n",
    "        plt.savefig(buffer, format=\"png\")\n",
    "        plt.close()\n",
    "        frame = imageio.v2.imread(buffer.getbuffer(), format=\"png\")\n",
    "        # @TODO: Uncomment to write the frames into images.\n",
    "        # im_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # save_path = \"/code/data/datasets/final_imgs\"\n",
    "        # filename = str(frame_idx) + \".jpg\"\n",
    "        # cv2.imwrite(os.path.join(save_path, filename), im_rgb)\n",
    "        writer.append_data(frame)\n",
    "        frame_idx += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
