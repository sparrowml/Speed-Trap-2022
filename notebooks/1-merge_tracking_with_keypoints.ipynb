{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose: This notebook produces the visualization for the tracklets and keypoints while aggregating all the predictions into a JSON file that organize the data frame by frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sparrow_datums import Boxes\n",
    "import numpy as np\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional\n",
    "import io\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from sparrow_datums import AugmentedBoxTracking, BoxTracking, FrameBoxes, PType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from speed_trapv3.keypoints.model import SegmentationModel\n",
    "from speed_trapv3.keypoints.config import Config as KeyConfig\n",
    "from speed_trapv3.keypoints.dataset import crop_and_resize,process_keypoints, keypoints_post_inference_processing\n",
    "from speed_trapv3.tracking.tracking import get_video_properties, transform_image, write_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/code/data/datasets/common_hall/source_video/25_resampled_vid.mp4\"\n",
    "video_save_path = '/code/data/datasets/common_hall/tracking_outputs/hard_coded_video.mp4'\n",
    "gz_path = '/code/data/datasets/tracking/predictions/hard_coded/hard_coded_vehicle.json.gz'\n",
    "json_save_path = '/code/data/datasets/common_hall/tracking_outputs/framewise_aggregation.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/code/data/datasets/common_hall/tracking_outputs/framewise_aggregation.json': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm /code/data/datasets/common_hall/tracking_outputs/framewise_aggregation.json\n",
    "!rm /code/data/datasets/common_hall/tracking_outputs/hard_coded_video.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoint_model = SegmentationModel().eval().cuda()\n",
    "keypoint_model.load(KeyConfig.trained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "599it [06:05,  1.64it/s]\n"
     ]
    }
   ],
   "source": [
    "reader = imageio.get_reader(video_path)\n",
    "fps = reader.get_meta_data()[\"fps\"]\n",
    "frame_border = True\n",
    "class_label: bool = False\n",
    "score_label: bool = False\n",
    "object_label: bool = True\n",
    "vehicle_chunk = AugmentedBoxTracking.from_box_tracking(\n",
    "    BoxTracking.from_file(gz_path)\n",
    ")\n",
    "vehicle_tracklet_list = BoxTracking.from_file(gz_path).to_dict()['object_ids']\n",
    "image_transform = T.Compose([T.ToTensor()])\n",
    "with imageio.get_writer(\n",
    "    video_save_path, mode=\"I\", fps=fps, macro_block_size=None\n",
    ") as writer:\n",
    "    aggregated_predictions = [] #Len is equal to to the number of frames.\n",
    "    frame_idx = 0\n",
    "    for img, vehicle_boxes in tqdm(zip(reader, vehicle_chunk)):\n",
    "        frame_log = {}\n",
    "        frame_log['frame_idx'] = frame_idx\n",
    "        frame_log['annotations'] = []\n",
    "        boxes = vehicle_boxes  # vehicle_boxes is a len = 16 list where unavailable objects are nan.\n",
    "        height, width = img.shape[:2]\n",
    "        fig = plt.figure(frameon=False, figsize=(width / 100, height / 100), dpi=100)\n",
    "        fig.add_axes((0, 0, 1, 1))\n",
    "        plt.imshow(img)\n",
    "        if frame_border:\n",
    "            plt.plot([450, 1280, 1280, 450, 450], [200, 200, 720, 720, 200], lw=2, c='green')\n",
    "        for i, box in enumerate(boxes.to_absolute()):\n",
    "            object_log = {}\n",
    "            if not np.isfinite(box.x):\n",
    "                continue\n",
    "            x1 = np.clip(box.x1, 2, width - 2)\n",
    "            x2 = np.clip(box.x2, 2, width - 2)\n",
    "            y1 = np.clip(box.y1, 2, height - 2)\n",
    "            y2 = np.clip(box.y2, 2, height - 2)\n",
    "            color: Optional[str] = None\n",
    "            text_strings: list[str] = []\n",
    "            if class_label:\n",
    "                text_strings.append(f\"class: {int(box.label)}\")\n",
    "                color = f\"C{int(box.label)}\"\n",
    "            if score_label:\n",
    "                text_strings.append(f\"score: {box.score:.2f}\")\n",
    "            if object_label:\n",
    "                text_strings.append(f\"object_id: {i}\")\n",
    "                if color is None:\n",
    "                    color = f\"C{i}\"\n",
    "            if color is None:\n",
    "                color = \"C0\"\n",
    "            plt.text(\n",
    "                x1 + 3,\n",
    "                y1 - 8,\n",
    "                \", \".join(text_strings),\n",
    "                backgroundcolor=(1, 1, 1, 0.5),\n",
    "                c=\"black\",\n",
    "                size=8,\n",
    "            )\n",
    "            plt.plot([x1, x2, x2, x1, x1], [y1, y1, y2, y2, y1], lw=2, c=color)\n",
    "            roi_w = x2 - x1\n",
    "            roi_h = y2 - y1\n",
    "            roi_resized = crop_and_resize(box.to_relative().array[:4], img, KeyConfig.image_crop_size[0],KeyConfig.image_crop_size[1])\n",
    "            roi_resized_w, roi_resized_h = roi_resized.size\n",
    "            x = image_transform(roi_resized)\n",
    "            x = torch.unsqueeze(x, 0).cuda()\n",
    "            keypoints = keypoint_model(x)['keypoints'][0].detach().cpu().numpy()\n",
    "            heatmaps = keypoint_model(x)['heatmaps'].detach().cpu()\n",
    "            keypoints_scores = list(np.amax(torch.flatten(heatmaps, 2).numpy(), axis=-1)[0])\n",
    "            keypoints = keypoints_post_inference_processing(\n",
    "                    keypoints, roi_resized_w, roi_resized_h, roi_w, roi_h, x1, y1\n",
    "                )\n",
    "            object_log['keypoints'] = [list(keypoints[0]), list(keypoints[1])]\n",
    "            object_log['keypoints_scores'] = [keypoints_scores[0].item(), keypoints_scores[1].item()]\n",
    "            object_log['object_id'] = i\n",
    "            object_log['object_tracklet_id'] = vehicle_tracklet_list[i]\n",
    "            object_log['bounding_box'] = list(box.array[:4])\n",
    "            frame_log[\"annotations\"].append(object_log)\n",
    "            plt.plot(keypoints[0][0], keypoints[0][1], marker='o', color=\"red\")\n",
    "            plt.plot(keypoints[1][0], keypoints[1][1], marker='o', color=\"blue\")\n",
    "        aggregated_predictions.append(frame_log)\n",
    "        frame_idx += 1\n",
    "        buffer = io.BytesIO()\n",
    "        plt.savefig(buffer, format=\"png\")\n",
    "        plt.close()\n",
    "        frame = imageio.v2.imread(buffer.getbuffer(), format=\"png\")\n",
    "        # Uncomment to write the frames into images.\n",
    "        # im_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # save_path = '/code/data/datasets/temp_imgs'\n",
    "        # filename = str(frame_idx) + \".jpg\"\n",
    "        # cv2.imwrite(os.path.join(save_path, filename), im_rgb)\n",
    "    \n",
    "        writer.append_data(frame)\n",
    "    out_file = open(json_save_path, \"w\")\n",
    "    json.dump(aggregated_predictions, out_file)\n",
    "    out_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
