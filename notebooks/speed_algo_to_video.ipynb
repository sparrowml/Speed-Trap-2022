{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we write the speed algorithm output into a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sparrow_datums import Boxes\n",
    "import numpy as np\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional\n",
    "import io\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from sparrow_datums import AugmentedBoxTracking, BoxTracking, FrameBoxes, PType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speed_trapv3.keypoints.model import SegmentationModel\n",
    "from speed_trapv3.keypoints.config import Config as KeyConfig\n",
    "from speed_trapv3.keypoints.dataset import crop_and_resize,process_keypoints, keypoints_post_inference_processing\n",
    "from speed_trapv3.tracking.tracking import get_video_properties, transform_image, write_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '/code/data/datasets/common_hall/source_video/25_resampled_vid.mp4'\n",
    "gz_path = '/code/data/datasets/tracking/predictions/hard_coded/hard_coded_vehicle.json.gz'\n",
    "video_save_path = '/code/data/datasets/common_hall/tracking_outputs/final_hardcoded_video.mp4'\n",
    "framewise_aggregation_path = '/code/data/datasets/common_hall/tracking_outputs/framewise_aggregation.json'\n",
    "objectwise_aggregation_path = '/code/data/datasets/common_hall/tracking_outputs/objectwise_aggregation.json'\n",
    "speed_log_path = '/code/data/datasets/common_hall/tracking_outputs/speed_log.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoint_model = SegmentationModel().eval().cuda()\n",
    "keypoint_model.load(KeyConfig.trained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(speed_log_path, 'r')\n",
    "speed_log = json.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(framewise_aggregation_path, 'r')\n",
    "framewise_aggregation = json.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(objectwise_aggregation_path, 'r')\n",
    "objectwise_aggregation = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "599it [05:06,  1.96it/s]\n"
     ]
    }
   ],
   "source": [
    "reader = imageio.get_reader(video_path)\n",
    "fps = reader.get_meta_data()[\"fps\"]\n",
    "frame_border = True\n",
    "class_label: bool = False\n",
    "score_label: bool = False\n",
    "object_label: bool = True\n",
    "vehicle_chunk = AugmentedBoxTracking.from_box_tracking(\n",
    "    BoxTracking.from_file(gz_path)\n",
    ")\n",
    "vehicle_tracklet_list = BoxTracking.from_file(gz_path).to_dict()['object_ids']\n",
    "speed_log_vehice_ids = list(speed_log.keys())\n",
    "image_transform = T.Compose([T.ToTensor()])\n",
    "with imageio.get_writer(\n",
    "    video_save_path, mode=\"I\", fps=fps, macro_block_size=None\n",
    ") as writer:\n",
    "    aggregated_predictions = [] #Len is equal to to the number of frames.\n",
    "    frame_idx = 0\n",
    "    object_count_log = {}\n",
    "    last_known_speed = {}\n",
    "    for img, vehicle_boxes in tqdm(zip(reader, vehicle_chunk)):\n",
    "        frame_log = {}\n",
    "        frame_log['frame_idx'] = frame_idx\n",
    "        frame_log['annotations'] = []\n",
    "        boxes = vehicle_boxes  # vehicle_boxes is a len = 16 list where unavailable objects are nan.\n",
    "        height, width = img.shape[:2]\n",
    "        fig = plt.figure(frameon=False, figsize=(width / 100, height / 100), dpi=100)\n",
    "        fig.add_axes((0, 0, 1, 1))\n",
    "        plt.imshow(img)\n",
    "        if frame_border:\n",
    "            plt.plot([450, 1280, 1280, 450, 450], [200, 200, 720, 720, 200], lw=2, c='green')\n",
    "        for i, box in enumerate(boxes.to_absolute()):\n",
    "            object_log = {}\n",
    "            if not np.isfinite(box.x):\n",
    "                continue\n",
    "            x1 = np.clip(box.x1, 2, width - 2)\n",
    "            x2 = np.clip(box.x2, 2, width - 2)\n",
    "            y1 = np.clip(box.y1, 2, height - 2)\n",
    "            y2 = np.clip(box.y2, 2, height - 2)\n",
    "            color: Optional[str] = None\n",
    "            text_strings: list[str] = []\n",
    "            if class_label:\n",
    "                text_strings.append(f\"class: {int(box.label)}\")\n",
    "                color = f\"C{int(box.label)}\"\n",
    "            if score_label:\n",
    "                text_strings.append(f\"score: {box.score:.2f}\")\n",
    "            if object_label:\n",
    "                if str(i) in speed_log_vehice_ids and str(frame_idx) in speed_log[str(i)] and speed_log[str(i)][str(frame_idx)] >= 0:\n",
    "                    text_strings.append(f\"object_id: {i}\")\n",
    "                    text_strings.append(f\"\\n current speed: {speed_log[str(i)][str(frame_idx)]} m/S\")\n",
    "                    last_known_speed[str(i)] = speed_log[str(i)][str(frame_idx)]\n",
    "                elif str(i) in speed_log_vehice_ids and str(i) in last_known_speed:\n",
    "                    text_strings.append(f\"object_id: {i}\")\n",
    "                    text_strings.append(f\"\\n current speed: {last_known_speed[str(i)]} m/S\")\n",
    "                else:\n",
    "                    text_strings.append(f\"object_id: {i}\")\n",
    "                if color is None:\n",
    "                    color = f\"C{i}\"\n",
    "            if color is None:\n",
    "                color = \"C0\"\n",
    "            plt.text(\n",
    "                x1 + 3,\n",
    "                y1 - 8,\n",
    "                \", \".join(text_strings),\n",
    "                backgroundcolor=(1, 1, 1, 0.5),\n",
    "                c=\"black\",\n",
    "                size=8,\n",
    "            )\n",
    "            plt.plot([x1, x2, x2, x1, x1], [y1, y1, y2, y2, y1], lw=2, c=color)\n",
    "            roi_w = x2 - x1\n",
    "            roi_h = y2 - y1\n",
    "            roi_resized = crop_and_resize(box.to_relative().array[:4], img, KeyConfig.image_crop_size[0],KeyConfig.image_crop_size[1])\n",
    "            roi_resized_w, roi_resized_h = roi_resized.size\n",
    "            x = image_transform(roi_resized)\n",
    "            x = torch.unsqueeze(x, 0).cuda()\n",
    "            keypoints = keypoint_model(x)['keypoints'][0].detach().cpu().numpy()\n",
    "            keypoints = keypoints_post_inference_processing(\n",
    "                    keypoints, roi_resized_w, roi_resized_h, roi_w, roi_h, x1, y1\n",
    "                )\n",
    "            object_log['keypoints'] = [list(keypoints[0]), list(keypoints[1])]\n",
    "            object_log['object_id'] = i\n",
    "            object_log['bounding_box'] = list(box.array[:4])\n",
    "            object_log['object_tracklet_id'] = vehicle_tracklet_list[i]\n",
    "            frame_log[\"annotations\"].append(object_log)\n",
    "            plt.plot(keypoints[0][0], keypoints[0][1], marker='o', color=\"red\")\n",
    "            plt.plot(keypoints[1][0], keypoints[1][1], marker='o', color=\"blue\")\n",
    "            if x1 > 800 and vehicle_tracklet_list[i] not in object_count_log:\n",
    "                object_count_log[vehicle_tracklet_list[i]] = True\n",
    "        aggregated_predictions.append(frame_log)\n",
    "        plt.text(\n",
    "            100,\n",
    "            100,\n",
    "            f\"Vehicle Count = {len(object_count_log)}\",\n",
    "            backgroundcolor=(1, 0.5, 1, 0.5),\n",
    "            c=\"black\",\n",
    "            # size=20,\n",
    "            fontsize=16\n",
    "            )\n",
    "        buffer = io.BytesIO()\n",
    "        plt.savefig(buffer, format=\"png\")\n",
    "        plt.close()\n",
    "        frame = imageio.v2.imread(buffer.getbuffer(), format=\"png\")\n",
    "        # Uncomment to write the frames into images.\n",
    "        im_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        save_path = '/code/data/datasets/final_imgs'\n",
    "        filename = str(frame_idx) + \".jpg\"\n",
    "        cv2.imwrite(os.path.join(save_path, filename), im_rgb)\n",
    "        writer.append_data(frame)\n",
    "        frame_idx += 1\n",
    "\n",
    "    # out_file = open(json_save_path, \"w\")\n",
    "    # json.dump(aggregated_predictions, out_file)\n",
    "    # out_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
